% !TeX root = p2p.tex

\section{Project code overview} \label{sec:code}

\setminted[text]{breaklines, tabsize=2, xleftmargin=\parindent} %xleftmargin=14pt}

The project code is based on the \emph{event driven} engine of the \peersim{} \cite{peersim} simulator.

As already stated stated, the algorithms presented in this report assume the communication is synchronized, which means that a computation step is not executed until all the messages sent at the previous step have reached the destination. This can be achieved with the event driven engine by letting the nodes exchange messages using a reliable \texttt{Transport} protocol and having them execute a periodic action (the computation step) at intervals larger than the maximum delay required by the \texttt{Transport} to deliver a message. Since messages are only sent during computation steps, this configuration guarantees that all the messages sent at one step are delivered before the next one is executed.

%As already stated, the algorithms presented in this report assume the communication is synchronized, meaning there are time windows in which the network nodes exchange messages interleaved with computation steps. This can be easily modeled with the event driven engine by including a reliable \texttt{Transport} protocol used by the \texttt{Node} instances to exchange messages, and having them execute a periodic action (an algorithm step) at intervals larger than the maximum delay required by the \texttt{Transport} to deliver a message. Since messages are only sent when a step is executed, this guarantees that all the messages sent at one step will be received before the next one. Using this model, the action performed upon receiving a message is simply to store it in a container to make it available when needed at a later time.

\subsection{Messages}

The nodes communicate by exchanging objects of the \texttt{Message} class. This class provides factory methods to generate \texttt{Message} objects that comply with the specification given in the algorithms description.

\subsection{Protocol classes}

The implementation of the \peersim{} protocols for \deccen{} and \multibfs{} is derived from the common base class \texttt{CentralityProtocol}. This class implements the common mechanisms needed by the synchronized protocols, in particular the support for the execution of periodic actions and the handling of the ``communication windows'' during which the network nodes exchange messages. Here is an excerpt of the class:
%The implementation of \deccen{} and \multibfs{} is organized in a hierarchy of \peersim{} protocol classes. The abstract base class \texttt{CentralityProtocol} provides methods to handle inter-node
%Protocol classes are organized in a hierarchy. Both \deccen{} and \multibfs{} protocols are derived from the abstract \texttt{CentralityProtocol} class. Other than the \texttt{EDProtocol} interface, this class also implements the \texttt{CDProtocol} interface to execute the periodic step action mentioned above:
\begin{minted}[breaklines=false]{text}
public abstract class CentralityProtocol implements EDProtocol,
    CDProtocol {
  private static String PAR_TRANSPORT = "transport";
  private int transportProtocolID;
  private List<Message> incoming;
  
  public SynchronousCentralityProtocol(String prefix) { ... }
  public Object clone() { ... }
  public void processEvent(Node node, int pid, Object event) { ... }
  protected void send(Node from, Node to, Message m, int pid) { ... }
  protected List<Message> getIncomingMessages() { ... }
  public abstract void nextCycle(Node self, int protocolID);
  ...
}
\end{minted}

The implementation of the \texttt{EDProtocol} interface is required by the event driven engine. The \texttt{EDProtocol.processEvent} method simply stores a newly received message in the \texttt{incoming} list, and notifies the \texttt{CentralitySimulation} control that a new message has been received (this control stops the simulation if no messages are sent in a time window):
\begin{minted}{text}
public void processEvent(Node node, int pid, Object event) {
  incoming.add((Message) event);
  CentralitySimulation.newMessage();
}
\end{minted}

%The \texttt{send} method is simply a convenience wrapper for \texttt{Transport.send}:
Messages are delivered by a \texttt{Transport} protocol, and can be sent by calling the \texttt{send} method which is a convenience wrapper for \texttt{Transport.send}:
\begin{minted}{text}
protected void send(Node from, Node to, Message m, int pid) {
  Transport tr = (Transport) from.getProtocol(transportProtocolID);
  tr.send(from, to, m, pid);
}
\end{minted}

The class also implements the \texttt{CDProtocol} interface to support the execution of periodic actions. This feature can be enabled by including in the simulation (through the configuration file) a \texttt{CDScheduler} component and configuring it to run a \texttt{CDProtocol} at regular steps, which causes the simulator to trigger the \texttt{CDProtocol.nextCycle} method on all the nodes that are running it.

When performing the experiments, the synchronous communication was configured using a \texttt{UniformRandomTransport} protocol to deliver messages with \texttt{mindelay} and \texttt{maxdelay} options of 15 and 200 milliseconds respectively, while the computation steps (implemented by the subclasses in the \texttt{nextCycle} method) were triggered by a \texttt{CDScheduler} at intervals of 500 milliseconds.  

\subsubsection{\deccen{} protocol implementation}

The \texttt{Deccen} class implements a \deccen{} node in the simulator. A node state consists of the shortest path information it collects and of the reports it has handled during the execution:
\begin{minted}{text}
public class Deccen extends SynchronousCentralityProtocol {
  private static class ShortestPathData {
    public final int count;
    public final int length;
    public ShortestPathData(int count, int length) { ... }
  }

  private static class OrderedPair<T1,T2> {
    public final T1 first;
    public final T2 second;
    public OrderedPair(T1 first, T2 second) { ... }
    ...
  }
  ...
  private Map<Node,ShortestPathData> shortestPathMap;
  private Set<OrderedPair<Long,Long>> handledReports;
  ...
  public void nextCycle(Node self, int protocolID) { ... }
  ...
}
\end{minted}
Whenever new \mdisc{} messages are received, additional information about the number and length of shortest paths toward a particular source becomes available: this information is stored in the \texttt{shortestPathMap} structure by adding a new \texttt{ShortestPathData} entry, paired with the source of the discovery. As the algorithm computes all the centrality indices, it needs both the distance from the source and the number of different paths counted (the \texttt{length} and \texttt{count} fields respectively). Reports about a source--destination pair $(s,t)$ are tracked by adding to the \texttt{handledReports} set an \texttt{Ordered\-Pair} of \texttt{Node} IDs.

The \texttt{nextCycle} method implements the actions specified by this report in section \ref{deccen:step}:
\begin{minted}{text}
public void nextCycle(Node self, int protocolID) {
  Map<Node,List<Message>> discoveryMap =
      new HashMap<Node,List<Message>>();
  List<Message> reportList = new LinkedList<Message>();
  parseIncomingMessages(discoveryMap, reportList);
  if (!discoveryMap.isEmpty())
    processDiscoveryMessages(self, protocolID, discoveryMap);
  if (!reportList.isEmpty())
    processReportMessages(self, protocolID, reportList);
}
\end{minted}
Messages received in the previous communication window are parsed by the \texttt{parseIncomingMessages} method: discovery messages with the same source are grouped together in the \texttt{discoveryMap} structure (using the source node as key), and reports are collected in the \texttt{reportList}.

\subsubsection{\multibfs{} protocol implementation}

The state of a \multibfs{} node consists of a \texttt{Map} to keep track of the various visits that are performed by the source nodes during the algorithm execution:

\begin{minted}{text}
public class MultiBFS extends SynchronousCentralityProtocol {
  private static class VisitState {
    ...
  }
  ...
  private Map<Node, VisitState> activeVisits;
  private Set<Node> completed;
  ...
  public void nextCycle(Node self, int protocolID) { ... }
  ...
  public boolean isWaiting(Node source) { ... }
  public boolean isActive(Node source) { ... }
  public boolean isCompleted(Node source) { ... }
}
\end{minted}
Recall that the state of a node is parametric with respect to each source of a visit. The state is \swait{\texttt{s}} if the \texttt{Node} instance \texttt{s} does not appear as key in the \texttt{activeVisits} map and neither is contained in the \texttt{completed} set; this is the initial state for any source since both structures are empty at the start of the protocol. When a node is in state \sact{\texttt{s}} an entry with key \texttt{s} is present in the \texttt{activeVisits} map. After a node has reported back to all the predecessors, it changes state \scomp{\texttt{s}} by removing the mapping from \texttt{activeVisits} and inserting \texttt{s} in the \texttt{completed} set.

Entries in the \texttt{activeVisits} map are used to store data while a node is in the ``active'' phase. A \texttt{VisitState} object is used to keep track of the predecessors and children sets, and to incrementally compute the values to be reported to the predecessor nodes:
\begin{minted}{text}
private static class VisitState {
  public Set<Node> predecessors;
  public Set<Node> siblings;
  public Set<Node> children;
  public int distanceFromSource;
  public int sigma;
  public long contributionSC;
  public double contributionBC;
  ...	
  public void accumulate(
      Node child, double bcc, long scc, int numSP) { ... }
}
\end{minted}
The \texttt{accumulate} method updates the local contributions of the source (stored in the \texttt{contributionSC} and \texttt{contributionBC} fields) by applying the recursive relations \eqref{eq:th:contrib:bc} and \eqref{eq:th:contrib:sc}, and it's invoked whenever a child node sends a report.

Finally, the \texttt{nextCycle} method which again follows the specification given earlier (in section \ref{multibfs:step}):
\begin{minted}{text}
public void nextCycle(Node self, int protocolID) {
  Map<Node,List<Message>> discoveryMap =
      new HashMap<Node,List<Message>>();
  List<Message> reportList = new LinkedList<Message>();
  parseIncomingMessages(discoveryMap, reportList);
  if (!discoveryMap.isEmpty())
    processDiscoveryMessages(self, protocolID, discoveryMap);
  if (!reportList.isEmpty())
    processReportMessages(reportList);
  reportNewCompleted(self, protocolID);
}
\end{minted}
Active visits for which all child nodes have reported are finalized with the \texttt{reportNewCompleted} method by integrating the contributions in the centrality accumulators and sending reports to the predecessors.