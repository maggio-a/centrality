% !TeX root = p2p.tex

\newcommand{\deccen}{\textsc{Deccen}}

\section{Introduction}

\section{Preliminary definitions and assumptions}

The task is to compute centrality indices for a given undirected graph $G = (V,E)$, which is assumed to be connected. Each node $v$ represents an independent agent with some given computational power, and that can communicate only with its neighbors $N_v = \{u \in V : \{u,v\} \in E\}$. A path $p(s,t)$ from a source $s$ to a destination $t$ is a sequence of edges that connects the two endpoints. The distance $d(u,v)$ between two nodes is the length of the shortest path that connects them, while the diameter $\Delta$ of the network is the maximum distance between any pair of nodes. Note that $d(u,v) = d(v,u)$ since the network is assumed to be connected, and $d(u,u) = 0$. A node $v$ is a predecessor of $w$ with respect to a source $s$ if $\{v,w\} \in E$ and $d(s,v) +1 = d(s,w)$. The \emph{predecessor set} $P_s(w)$ of $w$ is the set of all predecessors of $w$ with respect to $s$.

The algorithms described in this report all assume an underlying synchronous model where the computation evolves in steps: at each step all the agents perform their computations independently and autonomously, and the messages they send at step $t$ are delivered to the destination at step $t+1$.

\section{The \deccen{} algorithm}

\section{Approximation of centrality indices}

The main issue with the \deccen{} algorithm is its computational cost both in terms of memory consumption and number of messages exchanged, rendering the algorithm impractical for networks of reasonable size.. In order to keep track of the forwarded report messages and guarantee the termination of the protocol each node needs to maintain a data structure of size $O(n^2)$, while the number of messages exchanged is $O(n^2m)$.

However, if we are for example interested in computing centrality indices in order to mitigate network congestion a simple estimation of the values could be sufficient. In the following I propose an approximation algorithm that adapts an idea originally developed for closeness centrality in \cite{ew2004} and expanded for the estimation of betweenness centrality in \cite{brandes2007}. The idea is to isolate the contribution of a single node $s$ to the centrality values of all the other nodes in the network and compute those contributions by solving a Single-Source-Shortest-Path problem starting from $s$. We can then compute the centrality of a node $v$ by adding the contributions of all the other nodes to $v$ (that is, by solving $n$ SSSP instances starting from all the nodes and accumulating the contributions locally). In our case, the SSSP problem is converted to a decentralized Breadth First Search.

The approximation algorithms described in \cite{ew2004,brandes2007} estimate the centrality values by solving the SSSP problems for a restricted set of source nodes.

\subsection{Contribution of a source to Closeness centrality}

The contribution of a source $s$ to the closeness centrality value of a node $v$ is trivial and is simply the distance $d(s,v)$ of $v$ from $s$:

\begin{equation}

\gamma(s|v) = d(s,v) .

\end{equation}

\subsection{Contribution of a source to Betweenness centrality}

To contribution of a source $s$ to the betweenness centrality of $v$ is the \emph{dependency} of $s$ on $v$ introduced in \cite{brandes2001}:

\begin{equation}
  
\delta(s|v) = \sum_{t \in V}^{} \frac{\sigma_{st}(v)}{\sigma_{st}}

\end{equation}
